name: Python runcode example
driver: local
cluster: http://localhost
shard: http://localhost
workflow:
  - data:
      executor: StepExecutor
  - input:
      executor: UnixPipeExecutor
      enabled: true
vars:
  output_file: zabbix_data_test.csv.gz
data:
  - tasks.file.write:
      path: zabbix_data_test.csv
      data: |
        "somekey1":"somevalue1";"somekey2":"somevalue2";"somekey3":"somevalue3"
        "somekey11":"somevalue12";"somekey22":"somevalue22";"somekey32":"somevalue32"
        "somekey12":"somevalue13";"somekey23":"somevalue23";"somekey33":"somevalue33"
  - tasks.pack.gz:
      input_file: zabbix_data_test.csv
      output_file: {{ vars.output_file }}
input:
  - io.file.read: {{ vars.output_file }}
  - pipes.unpack.unpack
  - pipes.python.runcode:
      python: python3.7
      run: |
        import json
        import sys

        for line in sys.stdin:
            data = dict(v.replace('"', '').split(':')[0:2] for v in line.strip().split(';'))
            sys.stdout.write(f'{{ vars.output_file }}: {json.dumps(data)}\n')
  - io.file.write: zabbix_piped_through_python.json
